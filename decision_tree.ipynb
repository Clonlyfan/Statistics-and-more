{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwwkv8x1ePdiaBNGIgTfFo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clonlyfan/Statistics-and-more/blob/main/decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4qVgeKfdaq_",
        "outputId": "79445049-4bfb-41f5-d28f-766d392d4086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Entropy of the dataset: 1.2638\n",
            "Initial Gini Impurity of the dataset: 0.5408\n",
            "\n",
            "Information Gain for each feature:\n",
            "Information Gain (Outlook): 0.5441\n",
            "Information Gain (Temperature): 0.4441\n",
            "Information Gain (Humidity): 0.4975\n",
            "Information Gain (Wind): 0.3532\n",
            "\n",
            "\n",
            "Gini Gain for each feature:\n",
            "Gini Gain (Outlook): -0.0314\n",
            "Gini Gain (Temperature): 0.1704\n",
            "Gini Gain (Humidity): 0.2234\n",
            "Gini Gain (Wind): 0.1380\n",
            "\n",
            "\n",
            "Detailed Explanation:\n",
            "\n",
            "1. Initial Entropy and Gini Impurity:\n",
            "   - **Entropy** measures the impurity or randomness in the target variable ('Play Tennis') of the entire dataset. A higher entropy value indicates more disorder, meaning the classes (Yes/No) are more mixed.\n",
            "     - Initial Entropy: 1.2638\n",
            "   - **Gini Impurity** is another measure of impurity. It represents the probability of misclassifying a randomly chosen instance if it were randomly labeled according to the class distribution in the dataset. A higher Gini impurity also indicates more disorder.\n",
            "     - Initial Gini Impurity: 0.5408\n",
            "\n",
            "2. Information Gain:\n",
            "   - **Information Gain** quantifies the reduction in entropy achieved by splitting the dataset based on a particular feature. It tells us how much more 'organized' the target variable becomes after partitioning the data according to the values of that feature.\n",
            "   - For each feature ('Outlook', 'Temperature', 'Humidity', 'Wind'):\n",
            "     - We calculate the entropy of the 'Play Tennis' outcome for each unique value within that feature (e.g., for 'Outlook': Sunny, Overcast, Rainy).\n",
            "     - Then, we calculate a weighted average of these entropies, where the weights are the proportion of instances belonging to each value of the feature.\n",
            "     - The Information Gain is the difference between the initial entropy of the dataset and this weighted average entropy. A higher Information Gain suggests that the feature is more effective in classifying the 'Play Tennis' outcome.\n",
            "   - Based on the calculated Information Gains:\n",
            "     - Information Gain (Outlook): 0.5441\n",
            "     - Information Gain (Temperature): 0.4441\n",
            "     - Information Gain (Humidity): 0.4975\n",
            "     - Information Gain (Wind): 0.3532\n",
            "\n",
            "\n",
            "3. Gini Gain:\n",
            "   - **Gini Gain** is analogous to Information Gain but uses Gini impurity instead of entropy. It measures the reduction in Gini impurity achieved by splitting the dataset on a particular feature.\n",
            "   - Similar to Information Gain, a higher Gini Gain for a feature indicates that splitting on that feature leads to a greater reduction in impurity in the resulting subsets, making it a potentially good feature for splitting in a decision tree.\n",
            "   - For each feature:\n",
            "     - Gini Gain (Outlook): -0.0314\n",
            "     - Gini Gain (Temperature): 0.1704\n",
            "     - Gini Gain (Humidity): 0.2234\n",
            "     - Gini Gain (Wind): 0.1380\n",
            "\n",
            "\n",
            "In the context of building a decision tree:\n",
            "- The feature with the **highest Information Gain** (if using entropy as the splitting criterion) or the **highest Gini Gain** (if using Gini impurity) would typically be chosen as the root node of the tree.\n",
            "- This is because these features provide the most information about the target variable and lead to the most homogeneous (pure) child nodes after the split.\n",
            "- The process would then be recursively applied to the child nodes until a stopping criterion is met (e.g., all instances in a node belong to the same class, or a maximum tree depth is reached).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def calculate_entropy(data):\n",
        "    \"\"\"Calculates the entropy of a dataset.\"\"\"\n",
        "    if len(data) == 0:\n",
        "        return 0\n",
        "    probabilities = data['Play Tennis'].value_counts(normalize=True)\n",
        "    entropy = -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
        "    return entropy\n",
        "\n",
        "def calculate_gini_impurity(data):\n",
        "    \"\"\"Calculates the Gini impurity of a dataset.\"\"\"\n",
        "    if len(data) == 0:\n",
        "        return 0\n",
        "    probabilities = data['Play Tennis'].value_counts(normalize=True)\n",
        "    gini = 1 - sum(p**2 for p in probabilities)\n",
        "    return gini\n",
        "\n",
        "def calculate_information_gain(data, attribute):\n",
        "    \"\"\"Calculates the information gain of splitting data on a given attribute.\"\"\"\n",
        "    total_entropy = calculate_entropy(data)\n",
        "    attribute_values = data[attribute].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in attribute_values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        proportion = len(subset) / len(data)\n",
        "        weighted_entropy += proportion * calculate_entropy(subset)\n",
        "\n",
        "    information_gain = total_entropy - weighted_entropy\n",
        "    return information_gain\n",
        "\n",
        "def calculate_gini_gain(data, attribute):\n",
        "    \"\"\"Calculates the Gini gain of splitting data on a given attribute.\"\"\"\n",
        "    total_gini = calculate_gini_impurity(data)\n",
        "    attribute_values = data[attribute].unique()\n",
        "    weighted_gini = 0\n",
        "\n",
        "    for value in attribute_values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        proportion = len(subset) / len(data)\n",
        "        weighted_gini += proportion * calculate_gini_impurity(subset)\n",
        "\n",
        "    gini_gain = total_gini - weighted_gini\n",
        "    return gini_gain\n",
        "\n",
        "# Load the data from the Excel file\n",
        "file_path = \"/content/gamedayornot.xlsx\"\n",
        "try:\n",
        "    df = pd.read_excel(file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "    exit()\n",
        "\n",
        "# Calculate initial entropy and Gini impurity of the entire dataset\n",
        "initial_entropy = calculate_entropy(df)\n",
        "initial_gini = calculate_gini_impurity(df)\n",
        "\n",
        "print(f\"Initial Entropy of the dataset: {initial_entropy:.4f}\")\n",
        "print(f\"Initial Gini Impurity of the dataset: {initial_gini:.4f}\\n\")\n",
        "\n",
        "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
        "\n",
        "# Calculate Information Gain for each feature\n",
        "print(\"Information Gain for each feature:\")\n",
        "for feature in features:\n",
        "    info_gain = calculate_information_gain(df, feature)\n",
        "    print(f\"Information Gain ({feature}): {info_gain:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate Gini Gain for each feature\n",
        "print(\"Gini Gain for each feature:\")\n",
        "for feature in features:\n",
        "    gini_gain = calculate_gini_gain(df, feature)\n",
        "    print(f\"Gini Gain ({feature}): {gini_gain:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Detailed Explanation:\n",
        "\n",
        "print(\"Detailed Explanation:\\n\")\n",
        "\n",
        "print(\"1. Initial Entropy and Gini Impurity:\")\n",
        "print(\"   - **Entropy** measures the impurity or randomness in the target variable ('Play Tennis') of the entire dataset. A higher entropy value indicates more disorder, meaning the classes (Yes/No) are more mixed.\")\n",
        "print(f\"     - Initial Entropy: {initial_entropy:.4f}\")\n",
        "print(\"   - **Gini Impurity** is another measure of impurity. It represents the probability of misclassifying a randomly chosen instance if it were randomly labeled according to the class distribution in the dataset. A higher Gini impurity also indicates more disorder.\")\n",
        "print(f\"     - Initial Gini Impurity: {initial_gini:.4f}\\n\")\n",
        "\n",
        "print(\"2. Information Gain:\")\n",
        "print(\"   - **Information Gain** quantifies the reduction in entropy achieved by splitting the dataset based on a particular feature. It tells us how much more 'organized' the target variable becomes after partitioning the data according to the values of that feature.\")\n",
        "print(\"   - For each feature ('Outlook', 'Temperature', 'Humidity', 'Wind'):\")\n",
        "print(\"     - We calculate the entropy of the 'Play Tennis' outcome for each unique value within that feature (e.g., for 'Outlook': Sunny, Overcast, Rainy).\")\n",
        "print(\"     - Then, we calculate a weighted average of these entropies, where the weights are the proportion of instances belonging to each value of the feature.\")\n",
        "print(\"     - The Information Gain is the difference between the initial entropy of the dataset and this weighted average entropy. A higher Information Gain suggests that the feature is more effective in classifying the 'Play Tennis' outcome.\")\n",
        "print(\"   - Based on the calculated Information Gains:\")\n",
        "for feature in features:\n",
        "    info_gain = calculate_information_gain(df, feature)\n",
        "    print(f\"     - Information Gain ({feature}): {info_gain:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"3. Gini Gain:\")\n",
        "print(\"   - **Gini Gain** is analogous to Information Gain but uses Gini impurity instead of entropy. It measures the reduction in Gini impurity achieved by splitting the dataset on a particular feature.\")\n",
        "print(\"   - Similar to Information Gain, a higher Gini Gain for a feature indicates that splitting on that feature leads to a greater reduction in impurity in the resulting subsets, making it a potentially good feature for splitting in a decision tree.\")\n",
        "print(\"   - For each feature:\")\n",
        "for feature in features:\n",
        "    gini_gain = calculate_gini_gain(df, feature)\n",
        "    print(f\"     - Gini Gain ({feature}): {gini_gain:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"In the context of building a decision tree:\")\n",
        "print(\"- The feature with the **highest Information Gain** (if using entropy as the splitting criterion) or the **highest Gini Gain** (if using Gini impurity) would typically be chosen as the root node of the tree.\")\n",
        "print(\"- This is because these features provide the most information about the target variable and lead to the most homogeneous (pure) child nodes after the split.\")\n",
        "print(\"- The process would then be recursively applied to the child nodes until a stopping criterion is met (e.g., all instances in a node belong to the same class, or a maximum tree depth is reached).\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import Counter\n",
        "from graphviz import Digraph\n",
        "from sklearn import tree  # For export_graphviz (though we'll adapt)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def calculate_entropy(data):\n",
        "    \"\"\"Calculates the entropy of a dataset.\"\"\"\n",
        "    if len(data) == 0:\n",
        "        return 0\n",
        "    probabilities = data['Play Tennis'].value_counts(normalize=True)\n",
        "    entropy = -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
        "    return entropy\n",
        "\n",
        "def calculate_gini_impurity(data):\n",
        "    \"\"\"Calculates the Gini impurity of a dataset.\"\"\"\n",
        "    if len(data) == 0:\n",
        "        return 0\n",
        "    probabilities = data['Play Tennis'].value_counts(normalize=True)\n",
        "    gini = 1 - sum(p**2 for p in probabilities)\n",
        "    return gini\n",
        "\n",
        "def calculate_information_gain(data, attribute):\n",
        "    \"\"\"Calculates the information gain of splitting data on a given attribute.\"\"\"\n",
        "    total_entropy = calculate_entropy(data)\n",
        "    attribute_values = data[attribute].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in attribute_values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        proportion = len(subset) / len(data)\n",
        "        weighted_entropy += proportion * calculate_entropy(subset)\n",
        "\n",
        "    information_gain = total_entropy - weighted_entropy\n",
        "    return information_gain\n",
        "\n",
        "def calculate_gini_gain(data, attribute):\n",
        "    \"\"\"Calculates the Gini gain of splitting data on a given attribute.\"\"\"\n",
        "    total_gini = calculate_gini_impurity(data)\n",
        "    attribute_values = data[attribute].unique()\n",
        "    weighted_gini = 0\n",
        "\n",
        "    for value in attribute_values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        proportion = len(subset) / len(data)\n",
        "        weighted_gini += proportion * calculate_gini_impurity(subset)\n",
        "\n",
        "    gini_gain = total_gini - weighted_gini\n",
        "    return gini_gain\n",
        "\n",
        "def build_decision_tree_for_plotting(data, features, target='Play Tennis', criterion='entropy', depth=0, max_depth=None, parent_name=None, edge_label=None, graph=None):\n",
        "    \"\"\"Recursively builds a decision tree and adds nodes/edges to a graphviz Digraph.\"\"\"\n",
        "    if graph is None:\n",
        "        graph = Digraph(comment='Decision Tree')\n",
        "        graph.attr('node', shape='box', style='rounded')\n",
        "\n",
        "    # Create current node label\n",
        "    if parent_name is None:\n",
        "        node_name = 'root'\n",
        "        impurity = calculate_entropy(data) if criterion == 'entropy' else calculate_gini_impurity(data)\n",
        "        graph.node(node_name, f\"Root\\n{criterion.capitalize()}: {impurity:.4f}\")\n",
        "    else:\n",
        "        impurity = calculate_entropy(data) if criterion == 'entropy' else calculate_gini_impurity(data)\n",
        "        class_counts = Counter(data[target])\n",
        "        majority_class = class_counts.most_common(1)[0][0]\n",
        "        node_name = f\"{parent_name}_{edge_label}_{depth}\"\n",
        "        graph.node(node_name, f\"{edge_label}\\n{criterion.capitalize()}: {impurity:.4f}\\nPredict: {majority_class}\")\n",
        "        graph.edge(parent_name, node_name, label=edge_label)\n",
        "\n",
        "    if len(data[target].unique()) == 1 or not features or (max_depth is not None and depth >= max_depth):\n",
        "        return graph\n",
        "\n",
        "    if criterion == 'entropy':\n",
        "        gains = {feature: calculate_information_gain(data, feature) for feature in features}\n",
        "        if not gains:  # No more features with gain\n",
        "            return graph\n",
        "        best_feature = max(gains, key=gains.get)\n",
        "    else:  # criterion == 'gini'\n",
        "        gains = {feature: calculate_gini_gain(data, feature) for feature in features}\n",
        "        if not gains:  # No more features with gain\n",
        "            return graph\n",
        "        best_feature = max(gains, key=gains.get)\n",
        "\n",
        "    remaining_features = [f for f in features if f != best_feature]\n",
        "\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        graph = build_decision_tree_for_plotting(subset, remaining_features, target, criterion, depth + 1, max_depth, node_name, str(value), graph)\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Load the data from the Excel file\n",
        "file_path = \"/content/gamedayornot.xlsx\"\n",
        "try:\n",
        "    df = pd.read_excel(file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "    exit()\n",
        "\n",
        "# --- Preprocessing for direct plotting (optional but can improve clarity) ---\n",
        "label_encoders = {}\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Play Tennis', axis=1)\n",
        "y = df['Play Tennis']\n",
        "feature_names = list(X.columns)\n",
        "class_names = y.unique().astype(str).tolist()\n",
        "\n",
        "# Build and plot the decision tree using Entropy\n",
        "tree_entropy_graph = build_decision_tree_for_plotting(df.copy(), feature_names, max_depth=2, criterion='entropy')\n",
        "print(\"\\nDecision Tree (Entropy):\")\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(tree_entropy_graph)\n",
        "except ImportError:\n",
        "    print(\"IPython not available, cannot display graph directly. Save to file:\")\n",
        "    tree_entropy_graph.render('decision_tree_entropy', view=True)\n",
        "\n",
        "# Build and plot the decision tree using Gini Impurity\n",
        "tree_gini_graph = build_decision_tree_for_plotting(df.copy(), feature_names, max_depth=2, criterion='gini')\n",
        "print(\"\\nDecision Tree (Gini):\")\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(tree_gini_graph)\n",
        "except ImportError:\n",
        "    print(\"IPython not available, cannot display graph directly. Save to file:\")\n",
        "    tree_gini_graph.render('decision_tree_gini', view=True)\n",
        "\n",
        "# --- Detailed Explanation (remains largely the same) ---\n",
        "\n",
        "print(\"\\nDetailed Explanation:\\n\")\n",
        "\n",
        "print(\"1. Initial Impurity Measures:\")\n",
        "initial_entropy = calculate_entropy(df[['Play Tennis']])\n",
        "initial_gini = calculate_gini_impurity(df[['Play Tennis']])\n",
        "print(f\"   - **Initial Entropy:** {initial_entropy:.4f}\")\n",
        "print(f\"   - **Initial Gini Impurity:** {initial_gini:.4f}\\n\")\n",
        "\n",
        "print(\"2. Information Gain and Gini Gain Calculation:\")\n",
        "info_gains = {feature: calculate_information_gain(df, feature) for feature in feature_names}\n",
        "gini_gains = {feature: calculate_gini_gain(df, feature) for feature in feature_names}\n",
        "print(\"   - Information Gain for each feature:\", info_gains)\n",
        "print(\"   - Gini Gain for each feature:\", gini_gains, \"\\n\")\n",
        "\n",
        "print(\"3. Building the Decision Tree for Plotting:\")\n",
        "print(\"   - The `build_decision_tree_for_plotting` function now directly creates a `graphviz.Digraph` object.\")\n",
        "print(\"   - It recursively selects the best feature to split on based on the chosen criterion.\")\n",
        "print(\"   - For each split, it adds nodes and edges to the `graph` object, labeling them with the feature, the split value, and the impurity at that node.\")\n",
        "print(\"   - Leaf nodes (at the maximum depth or when pure) will show the predicted majority class.\\n\")\n",
        "\n",
        "print(\"4. Displaying the Decision Tree:\")\n",
        "print(\"   - The resulting `graphviz.Digraph` object is then displayed using `IPython.display.display(graph)`. If you are not in an IPython environment (like Colab), it will attempt to save the graph to a file (e.g., 'decision_tree_entropy.pdf').\\n\")\n",
        "\n",
        "print(\"5. Interpreting the Decision Tree Plot:\")\n",
        "print(\"   - The root node represents the initial decision based on the feature with the highest gain.\")\n",
        "print(\"   - Each edge represents a value of the splitting feature.\")\n",
        "print(\"   - Internal nodes represent further decisions.\")\n",
        "print(\"   - Leaf nodes show the predicted class ('0' or '1' in this encoded example, which you can map back using `label_encoders['Play Tennis'].classes_`).\")\n",
        "print(\"   - The impurity (Entropy or Gini) is shown at each node, decreasing as you go down the tree (ideally).\")\n",
        "\n",
        "print(\"\\nFurther Steps:\")\n",
        "print(\"- You can increase the `max_depth` parameter in `build_decision_tree_for_plotting` to see a deeper tree.\")\n",
        "print(\"- For a more detailed tree, you might need to handle categorical features more explicitly within the splitting logic if the simple label encoding isn't sufficient for your understanding.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hAWXW6aisLxs",
        "outputId": "58cf18b9-37c7-43e5-f939-da10699603c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree (Entropy):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"1264pt\" height=\"254pt\"\n viewBox=\"0.00 0.00 1264.00 254.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 250)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-250 1260,-250 1260,4 -4,4\"/>\n<!-- root -->\n<g id=\"node1\" class=\"node\">\n<title>root</title>\n<path fill=\"none\" stroke=\"black\" d=\"M857.5,-246C857.5,-246 776.5,-246 776.5,-246 770.5,-246 764.5,-240 764.5,-234 764.5,-234 764.5,-220 764.5,-220 764.5,-214 770.5,-208 776.5,-208 776.5,-208 857.5,-208 857.5,-208 863.5,-208 869.5,-214 869.5,-220 869.5,-220 869.5,-234 869.5,-234 869.5,-240 863.5,-246 857.5,-246\"/>\n<text text-anchor=\"middle\" x=\"817\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">Root</text>\n<text text-anchor=\"middle\" x=\"817\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: 1.7472</text>\n</g>\n<!-- root_3_1 -->\n<g id=\"node2\" class=\"node\">\n<title>root_3_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M223.5,-157C223.5,-157 142.5,-157 142.5,-157 136.5,-157 130.5,-151 130.5,-145 130.5,-145 130.5,-116 130.5,-116 130.5,-110 136.5,-104 142.5,-104 142.5,-104 223.5,-104 223.5,-104 229.5,-104 235.5,-110 235.5,-116 235.5,-116 235.5,-145 235.5,-145 235.5,-151 229.5,-157 223.5,-157\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: 0.9710</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root&#45;&gt;root_3_1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>root&#45;&gt;root_3_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M764.31,-218.15C648.27,-200.85 371.06,-159.53 246.05,-140.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"246.28,-137.39 235.87,-139.38 245.25,-144.32 246.28,-137.39\"/>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n</g>\n<!-- root_0_1 -->\n<g id=\"node5\" class=\"node\">\n<title>root_0_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M539.5,-157C539.5,-157 458.5,-157 458.5,-157 452.5,-157 446.5,-151 446.5,-145 446.5,-145 446.5,-116 446.5,-116 446.5,-110 452.5,-104 458.5,-104 458.5,-104 539.5,-104 539.5,-104 545.5,-104 551.5,-110 551.5,-116 551.5,-116 551.5,-145 551.5,-145 551.5,-151 545.5,-157 539.5,-157\"/>\n<text text-anchor=\"middle\" x=\"499\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"499\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: 0.8113</text>\n<text text-anchor=\"middle\" x=\"499\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root&#45;&gt;root_0_1 -->\n<g id=\"edge4\" class=\"edge\">\n<title>root&#45;&gt;root_0_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M764.49,-210.4C708.68,-193.81 620.46,-167.6 561.21,-149.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"562.17,-146.62 551.59,-147.13 560.18,-153.33 562.17,-146.62\"/>\n<text text-anchor=\"middle\" x=\"699.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_1_1 -->\n<g id=\"node9\" class=\"node\">\n<title>root_1_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M731.5,-157C731.5,-157 650.5,-157 650.5,-157 644.5,-157 638.5,-151 638.5,-145 638.5,-145 638.5,-116 638.5,-116 638.5,-110 644.5,-104 650.5,-104 650.5,-104 731.5,-104 731.5,-104 737.5,-104 743.5,-110 743.5,-116 743.5,-116 743.5,-145 743.5,-145 743.5,-151 737.5,-157 731.5,-157\"/>\n<text text-anchor=\"middle\" x=\"691\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"691\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: 0.9710</text>\n<text text-anchor=\"middle\" x=\"691\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root&#45;&gt;root_1_1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>root&#45;&gt;root_1_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M792.71,-207.78C775.94,-195.2 753.19,-178.14 733.47,-163.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"735.32,-160.37 725.22,-157.17 731.12,-165.97 735.32,-160.37\"/>\n<text text-anchor=\"middle\" x=\"772.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- root_2_1 -->\n<g id=\"node13\" class=\"node\">\n<title>root_2_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M860,-157C860,-157 774,-157 774,-157 768,-157 762,-151 762,-145 762,-145 762,-116 762,-116 762,-110 768,-104 774,-104 774,-104 860,-104 860,-104 866,-104 872,-110 872,-116 872,-116 872,-145 872,-145 872,-151 866,-157 860,-157\"/>\n<text text-anchor=\"middle\" x=\"817\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n<text text-anchor=\"middle\" x=\"817\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"817\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 3</text>\n</g>\n<!-- root&#45;&gt;root_2_1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>root&#45;&gt;root_2_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M817,-207.78C817,-196.33 817,-181.16 817,-167.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"820.5,-167.17 817,-157.17 813.5,-167.17 820.5,-167.17\"/>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- root_5_1 -->\n<g id=\"node14\" class=\"node\">\n<title>root_5_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M988,-157C988,-157 902,-157 902,-157 896,-157 890,-151 890,-145 890,-145 890,-116 890,-116 890,-110 896,-104 902,-104 902,-104 988,-104 988,-104 994,-104 1000,-110 1000,-116 1000,-116 1000,-145 1000,-145 1000,-151 994,-157 988,-157\"/>\n<text text-anchor=\"middle\" x=\"945\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n<text text-anchor=\"middle\" x=\"945\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"945\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 3</text>\n</g>\n<!-- root&#45;&gt;root_5_1 -->\n<g id=\"edge13\" class=\"edge\">\n<title>root&#45;&gt;root_5_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M841.68,-207.78C858.79,-195.15 882.03,-177.99 902.13,-163.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"904.27,-165.92 910.23,-157.17 900.11,-160.29 904.27,-165.92\"/>\n<text text-anchor=\"middle\" x=\"888.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n</g>\n<!-- root_6_1 -->\n<g id=\"node15\" class=\"node\">\n<title>root_6_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1116,-157C1116,-157 1030,-157 1030,-157 1024,-157 1018,-151 1018,-145 1018,-145 1018,-116 1018,-116 1018,-110 1024,-104 1030,-104 1030,-104 1116,-104 1116,-104 1122,-104 1128,-110 1128,-116 1128,-116 1128,-145 1128,-145 1128,-151 1122,-157 1116,-157\"/>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">6</text>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"1073\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 3</text>\n</g>\n<!-- root&#45;&gt;root_6_1 -->\n<g id=\"edge14\" class=\"edge\">\n<title>root&#45;&gt;root_6_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M868.92,-207.88C905.46,-195.01 955.71,-177.05 1008.38,-157.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1009.77,-160.41 1017.89,-153.6 1007.3,-153.86 1009.77,-160.41\"/>\n<text text-anchor=\"middle\" x=\"960.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">6</text>\n</g>\n<!-- root_4_1 -->\n<g id=\"node16\" class=\"node\">\n<title>root_4_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1244,-157C1244,-157 1158,-157 1158,-157 1152,-157 1146,-151 1146,-145 1146,-145 1146,-116 1146,-116 1146,-110 1152,-104 1158,-104 1158,-104 1244,-104 1244,-104 1250,-104 1256,-110 1256,-116 1256,-116 1256,-145 1256,-145 1256,-151 1250,-157 1244,-157\"/>\n<text text-anchor=\"middle\" x=\"1201\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n<text text-anchor=\"middle\" x=\"1201\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"1201\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 3</text>\n</g>\n<!-- root&#45;&gt;root_4_1 -->\n<g id=\"edge15\" class=\"edge\">\n<title>root&#45;&gt;root_4_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M869.5,-217.45C931.4,-206.77 1037.34,-186.56 1135.88,-157.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1137.14,-160.43 1145.7,-154.19 1135.11,-153.73 1137.14,-160.43\"/>\n<text text-anchor=\"middle\" x=\"1071.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n</g>\n<!-- root_3_1_0_2 -->\n<g id=\"node3\" class=\"node\">\n<title>root_3_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M98,-53C98,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 98,0 98,0 104,0 110,-6 110,-12 110,-12 110,-41 110,-41 110,-47 104,-53 98,-53\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root_3_1&#45;&gt;root_3_1_0_2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>root_3_1&#45;&gt;root_3_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.7,-103.76C133.87,-90.35 113.14,-73.83 95.27,-59.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.29,-56.73 87.29,-53.23 92.93,-62.2 97.29,-56.73\"/>\n<text text-anchor=\"middle\" x=\"130.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_3_1_1_2 -->\n<g id=\"node4\" class=\"node\">\n<title>root_3_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M226,-53C226,-53 140,-53 140,-53 134,-53 128,-47 128,-41 128,-41 128,-12 128,-12 128,-6 134,0 140,0 140,0 226,0 226,0 232,0 238,-6 238,-12 238,-12 238,-41 238,-41 238,-47 232,-53 226,-53\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_3_1&#45;&gt;root_3_1_1_2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>root_3_1&#45;&gt;root_3_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M183,-103.76C183,-91.56 183,-76.78 183,-63.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186.5,-63.23 183,-53.23 179.5,-63.23 186.5,-63.23\"/>\n<text text-anchor=\"middle\" x=\"186.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- root_0_1_1_2 -->\n<g id=\"node6\" class=\"node\">\n<title>root_0_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M349.5,-53C349.5,-53 268.5,-53 268.5,-53 262.5,-53 256.5,-47 256.5,-41 256.5,-41 256.5,-12 256.5,-12 256.5,-6 262.5,0 268.5,0 268.5,0 349.5,0 349.5,0 355.5,0 361.5,-6 361.5,-12 361.5,-12 361.5,-41 361.5,-41 361.5,-47 355.5,-53 349.5,-53\"/>\n<text text-anchor=\"middle\" x=\"309\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: 1.0000</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 2</text>\n</g>\n<!-- root_0_1&#45;&gt;root_0_1_1_2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>root_0_1&#45;&gt;root_0_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M451.05,-103.76C425.08,-89.82 392.82,-72.5 365.62,-57.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"367.07,-54.7 356.6,-53.05 363.76,-60.87 367.07,-54.7\"/>\n<text text-anchor=\"middle\" x=\"419.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- root_0_1_0_2 -->\n<g id=\"node7\" class=\"node\">\n<title>root_0_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M478,-53C478,-53 392,-53 392,-53 386,-53 380,-47 380,-41 380,-41 380,-12 380,-12 380,-6 386,0 392,0 392,0 478,0 478,0 484,0 490,-6 490,-12 490,-12 490,-41 490,-41 490,-47 484,-53 478,-53\"/>\n<text text-anchor=\"middle\" x=\"435\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"435\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"435\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_0_1&#45;&gt;root_0_1_0_2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>root_0_1&#45;&gt;root_0_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M482.85,-103.76C474.89,-91.08 465.18,-75.6 456.6,-61.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"459.42,-59.84 451.14,-53.23 453.49,-63.56 459.42,-59.84\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_0_1_2_2 -->\n<g id=\"node8\" class=\"node\">\n<title>root_0_1_2_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M606,-53C606,-53 520,-53 520,-53 514,-53 508,-47 508,-41 508,-41 508,-12 508,-12 508,-6 514,0 520,0 520,0 606,0 606,0 612,0 618,-6 618,-12 618,-12 618,-41 618,-41 618,-47 612,-53 606,-53\"/>\n<text text-anchor=\"middle\" x=\"563\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n<text text-anchor=\"middle\" x=\"563\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"563\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_0_1&#45;&gt;root_0_1_2_2 -->\n<g id=\"edge7\" class=\"edge\">\n<title>root_0_1&#45;&gt;root_0_1_2_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M515.15,-103.76C523.11,-91.08 532.82,-75.6 541.4,-61.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"544.51,-63.56 546.86,-53.23 538.58,-59.84 544.51,-63.56\"/>\n<text text-anchor=\"middle\" x=\"538.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- root_1_1_2_2 -->\n<g id=\"node10\" class=\"node\">\n<title>root_1_1_2_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M734,-53C734,-53 648,-53 648,-53 642,-53 636,-47 636,-41 636,-41 636,-12 636,-12 636,-6 642,0 648,0 648,0 734,0 734,0 740,0 746,-6 746,-12 746,-12 746,-41 746,-41 746,-47 740,-53 734,-53\"/>\n<text text-anchor=\"middle\" x=\"691\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n<text text-anchor=\"middle\" x=\"691\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"691\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_1_1&#45;&gt;root_1_1_2_2 -->\n<g id=\"edge9\" class=\"edge\">\n<title>root_1_1&#45;&gt;root_1_1_2_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M691,-103.76C691,-91.56 691,-76.78 691,-63.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"694.5,-63.23 691,-53.23 687.5,-63.23 694.5,-63.23\"/>\n<text text-anchor=\"middle\" x=\"694.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- root_1_1_0_2 -->\n<g id=\"node11\" class=\"node\">\n<title>root_1_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M862,-53C862,-53 776,-53 776,-53 770,-53 764,-47 764,-41 764,-41 764,-12 764,-12 764,-6 770,0 776,0 776,0 862,0 862,0 868,0 874,-6 874,-12 874,-12 874,-41 874,-41 874,-47 868,-53 862,-53\"/>\n<text text-anchor=\"middle\" x=\"819\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"819\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"819\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root_1_1&#45;&gt;root_1_1_0_2 -->\n<g id=\"edge10\" class=\"edge\">\n<title>root_1_1&#45;&gt;root_1_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M723.3,-103.76C740.13,-90.35 760.86,-73.83 778.73,-59.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"781.07,-62.2 786.71,-53.23 776.71,-56.73 781.07,-62.2\"/>\n<text text-anchor=\"middle\" x=\"766.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_1_1_1_2 -->\n<g id=\"node12\" class=\"node\">\n<title>root_1_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M990,-53C990,-53 904,-53 904,-53 898,-53 892,-47 892,-41 892,-41 892,-12 892,-12 892,-6 898,0 904,0 904,0 990,0 990,0 996,0 1002,-6 1002,-12 1002,-12 1002,-41 1002,-41 1002,-47 996,-53 990,-53\"/>\n<text text-anchor=\"middle\" x=\"947\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"947\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Entropy: &#45;0.0000</text>\n<text text-anchor=\"middle\" x=\"947\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root_1_1&#45;&gt;root_1_1_1_2 -->\n<g id=\"edge11\" class=\"edge\">\n<title>root_1_1&#45;&gt;root_1_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M743.74,-107.74C746.87,-106.47 749.98,-105.21 753,-104 807.78,-81.99 823.75,-76.36 882.46,-53.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"883.83,-56.42 891.85,-49.5 881.26,-49.91 883.83,-56.42\"/>\n<text text-anchor=\"middle\" x=\"839.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x78b0249b9b50>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree (Gini):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"614pt\" height=\"254pt\"\n viewBox=\"0.00 0.00 614.00 254.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 250)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-250 610,-250 610,4 -4,4\"/>\n<!-- root -->\n<g id=\"node1\" class=\"node\">\n<title>root</title>\n<path fill=\"none\" stroke=\"black\" d=\"M438,-246C438,-246 376,-246 376,-246 370,-246 364,-240 364,-234 364,-234 364,-220 364,-220 364,-214 370,-208 376,-208 376,-208 438,-208 438,-208 444,-208 450,-214 450,-220 450,-220 450,-234 450,-234 450,-240 444,-246 438,-246\"/>\n<text text-anchor=\"middle\" x=\"407\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\">Root</text>\n<text text-anchor=\"middle\" x=\"407\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.6728</text>\n</g>\n<!-- root_0_1 -->\n<g id=\"node2\" class=\"node\">\n<title>root_0_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M230,-157C230,-157 168,-157 168,-157 162,-157 156,-151 156,-145 156,-145 156,-116 156,-116 156,-110 162,-104 168,-104 168,-104 230,-104 230,-104 236,-104 242,-110 242,-116 242,-116 242,-145 242,-145 242,-151 236,-157 230,-157\"/>\n<text text-anchor=\"middle\" x=\"199\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"199\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.5714</text>\n<text text-anchor=\"middle\" x=\"199\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root&#45;&gt;root_0_1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>root&#45;&gt;root_0_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M366.9,-207.78C334.06,-192.86 287.35,-171.64 251.53,-155.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"252.76,-152.08 242.21,-151.13 249.86,-158.45 252.76,-152.08\"/>\n<text text-anchor=\"middle\" x=\"331.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_1_1 -->\n<g id=\"node6\" class=\"node\">\n<title>root_1_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M438,-157C438,-157 376,-157 376,-157 370,-157 364,-151 364,-145 364,-145 364,-116 364,-116 364,-110 370,-104 376,-104 376,-104 438,-104 438,-104 444,-104 450,-110 450,-116 450,-116 450,-145 450,-145 450,-151 444,-157 438,-157\"/>\n<text text-anchor=\"middle\" x=\"407\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"407\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.2449</text>\n<text text-anchor=\"middle\" x=\"407\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root&#45;&gt;root_1_1 -->\n<g id=\"edge5\" class=\"edge\">\n<title>root&#45;&gt;root_1_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M407,-207.78C407,-196.33 407,-181.16 407,-167.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"410.5,-167.17 407,-157.17 403.5,-167.17 410.5,-167.17\"/>\n<text text-anchor=\"middle\" x=\"410.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- root_2_1 -->\n<g id=\"node10\" class=\"node\">\n<title>root_2_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M542,-157C542,-157 480,-157 480,-157 474,-157 468,-151 468,-145 468,-145 468,-116 468,-116 468,-110 474,-104 480,-104 480,-104 542,-104 542,-104 548,-104 554,-110 554,-116 554,-116 554,-145 554,-145 554,-151 548,-157 542,-157\"/>\n<text text-anchor=\"middle\" x=\"511\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n<text text-anchor=\"middle\" x=\"511\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.0000</text>\n<text text-anchor=\"middle\" x=\"511\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 3</text>\n</g>\n<!-- root&#45;&gt;root_2_1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>root&#45;&gt;root_2_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M427.05,-207.78C440.65,-195.43 459,-178.75 475.07,-164.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"477.71,-166.48 482.75,-157.17 473,-161.3 477.71,-166.48\"/>\n<text text-anchor=\"middle\" x=\"465.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- root_0_1_3_2 -->\n<g id=\"node3\" class=\"node\">\n<title>root_0_1_3_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M74,-53C74,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 74,0 74,0 80,0 86,-6 86,-12 86,-12 86,-41 86,-41 86,-47 80,-53 74,-53\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n<text text-anchor=\"middle\" x=\"43\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.0000</text>\n<text text-anchor=\"middle\" x=\"43\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root_0_1&#45;&gt;root_0_1_3_2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>root_0_1&#45;&gt;root_0_1_3_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M159.63,-103.76C138.68,-90.06 112.74,-73.1 90.65,-58.66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"92.37,-55.6 82.08,-53.05 88.54,-61.46 92.37,-55.6\"/>\n<text text-anchor=\"middle\" x=\"134.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n</g>\n<!-- root_0_1_0_2 -->\n<g id=\"node4\" class=\"node\">\n<title>root_0_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M178,-53C178,-53 116,-53 116,-53 110,-53 104,-47 104,-41 104,-41 104,-12 104,-12 104,-6 110,0 116,0 116,0 178,0 178,0 184,0 190,-6 190,-12 190,-12 190,-41 190,-41 190,-47 184,-53 178,-53\"/>\n<text text-anchor=\"middle\" x=\"147\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"147\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.5000</text>\n<text text-anchor=\"middle\" x=\"147\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 2</text>\n</g>\n<!-- root_0_1&#45;&gt;root_0_1_0_2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>root_0_1&#45;&gt;root_0_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M185.88,-103.76C179.47,-91.2 171.67,-75.9 164.75,-62.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167.78,-60.55 160.12,-53.23 161.54,-63.73 167.78,-60.55\"/>\n<text text-anchor=\"middle\" x=\"180.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_0_1_1_2 -->\n<g id=\"node5\" class=\"node\">\n<title>root_0_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M282,-53C282,-53 220,-53 220,-53 214,-53 208,-47 208,-41 208,-41 208,-12 208,-12 208,-6 214,0 220,0 220,0 282,0 282,0 288,0 294,-6 294,-12 294,-12 294,-41 294,-41 294,-47 288,-53 282,-53\"/>\n<text text-anchor=\"middle\" x=\"251\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.5000</text>\n<text text-anchor=\"middle\" x=\"251\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_0_1&#45;&gt;root_0_1_1_2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>root_0_1&#45;&gt;root_0_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M212.12,-103.76C218.53,-91.2 226.33,-75.9 233.25,-62.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"236.46,-63.73 237.88,-53.23 230.22,-60.55 236.46,-63.73\"/>\n<text text-anchor=\"middle\" x=\"232.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n<!-- root_1_1_2_2 -->\n<g id=\"node7\" class=\"node\">\n<title>root_1_1_2_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M386,-53C386,-53 324,-53 324,-53 318,-53 312,-47 312,-41 312,-41 312,-12 312,-12 312,-6 318,0 324,0 324,0 386,0 386,0 392,0 398,-6 398,-12 398,-12 398,-41 398,-41 398,-47 392,-53 386,-53\"/>\n<text text-anchor=\"middle\" x=\"355\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n<text text-anchor=\"middle\" x=\"355\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.0000</text>\n<text text-anchor=\"middle\" x=\"355\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_1_1&#45;&gt;root_1_1_2_2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>root_1_1&#45;&gt;root_1_1_2_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M393.88,-103.76C387.47,-91.2 379.67,-75.9 372.75,-62.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"375.78,-60.55 368.12,-53.23 369.54,-63.73 375.78,-60.55\"/>\n<text text-anchor=\"middle\" x=\"388.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n</g>\n<!-- root_1_1_0_2 -->\n<g id=\"node8\" class=\"node\">\n<title>root_1_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M490,-53C490,-53 428,-53 428,-53 422,-53 416,-47 416,-41 416,-41 416,-12 416,-12 416,-6 422,0 428,0 428,0 490,0 490,0 496,0 502,-6 502,-12 502,-12 502,-41 502,-41 502,-47 496,-53 490,-53\"/>\n<text text-anchor=\"middle\" x=\"459\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n<text text-anchor=\"middle\" x=\"459\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.5000</text>\n<text text-anchor=\"middle\" x=\"459\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 0</text>\n</g>\n<!-- root_1_1&#45;&gt;root_1_1_0_2 -->\n<g id=\"edge7\" class=\"edge\">\n<title>root_1_1&#45;&gt;root_1_1_0_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M420.12,-103.76C426.53,-91.2 434.33,-75.9 441.25,-62.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"444.46,-63.73 445.88,-53.23 438.22,-60.55 444.46,-63.73\"/>\n<text text-anchor=\"middle\" x=\"440.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- root_1_1_1_2 -->\n<g id=\"node9\" class=\"node\">\n<title>root_1_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M594,-53C594,-53 532,-53 532,-53 526,-53 520,-47 520,-41 520,-41 520,-12 520,-12 520,-6 526,0 532,0 532,0 594,0 594,0 600,0 606,-6 606,-12 606,-12 606,-41 606,-41 606,-47 600,-53 594,-53\"/>\n<text text-anchor=\"middle\" x=\"563\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n<text text-anchor=\"middle\" x=\"563\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Gini: 0.0000</text>\n<text text-anchor=\"middle\" x=\"563\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Predict: 1</text>\n</g>\n<!-- root_1_1&#45;&gt;root_1_1_1_2 -->\n<g id=\"edge8\" class=\"edge\">\n<title>root_1_1&#45;&gt;root_1_1_1_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M446.37,-103.76C467.32,-90.06 493.26,-73.1 515.35,-58.66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"517.46,-61.46 523.92,-53.05 513.63,-55.6 517.46,-61.46\"/>\n<text text-anchor=\"middle\" x=\"497.5\" y=\"-74.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x78b037bdca50>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Explanation:\n",
            "\n",
            "1. Initial Impurity Measures:\n",
            "   - **Initial Entropy:** 1.7472\n",
            "   - **Initial Gini Impurity:** 0.6728\n",
            "\n",
            "2. Information Gain and Gini Gain Calculation:\n",
            "   - Information Gain for each feature: {'Outlook': 1.0274661727300884, 'Temperature': 0.927451224964519, 'Humidity': 0.9808786470580716, 'Wind': 0.8365916681089789}\n",
            "   - Gini Gain for each feature: {'Outlook': 0.3228395061728395, 'Temperature': 0.30246913580246915, 'Humidity': 0.35537918871252205, 'Wind': 0.2700617283950617} \n",
            "\n",
            "3. Building the Decision Tree for Plotting:\n",
            "   - The `build_decision_tree_for_plotting` function now directly creates a `graphviz.Digraph` object.\n",
            "   - It recursively selects the best feature to split on based on the chosen criterion.\n",
            "   - For each split, it adds nodes and edges to the `graph` object, labeling them with the feature, the split value, and the impurity at that node.\n",
            "   - Leaf nodes (at the maximum depth or when pure) will show the predicted majority class.\n",
            "\n",
            "4. Displaying the Decision Tree:\n",
            "   - The resulting `graphviz.Digraph` object is then displayed using `IPython.display.display(graph)`. If you are not in an IPython environment (like Colab), it will attempt to save the graph to a file (e.g., 'decision_tree_entropy.pdf').\n",
            "\n",
            "5. Interpreting the Decision Tree Plot:\n",
            "   - The root node represents the initial decision based on the feature with the highest gain.\n",
            "   - Each edge represents a value of the splitting feature.\n",
            "   - Internal nodes represent further decisions.\n",
            "   - Leaf nodes show the predicted class ('0' or '1' in this encoded example, which you can map back using `label_encoders['Play Tennis'].classes_`).\n",
            "   - The impurity (Entropy or Gini) is shown at each node, decreasing as you go down the tree (ideally).\n",
            "\n",
            "Further Steps:\n",
            "- You can increase the `max_depth` parameter in `build_decision_tree_for_plotting` to see a deeper tree.\n",
            "- For a more detailed tree, you might need to handle categorical features more explicitly within the splitting logic if the simple label encoding isn't sufficient for your understanding.\n"
          ]
        }
      ]
    }
  ]
}